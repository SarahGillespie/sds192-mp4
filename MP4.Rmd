---
title: "MP4"
author: "Sarah Gillespie, Berry Williams, Eva Putnam"
date: "2019-05-04"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r StartingItems, message=FALSE, warning = FALSE}
library(mdsr)
library(RMySQL)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(sf)
library(leaflet)
library(lwgeom)
library(wordcountaddin)
library(lubridate)
library(rtweet)
library(RColorBrewer)
library(ggthemes)
```

```{r SQLData, message=FALSE, warning = FALSE}
library(RMySQL)
db <- dbConnect(MySQL(), 
                host = "scidb.smith.edu", 
                user = "mth292", 
                password = "RememberPi", 
                dbname = "citibike")

class(db)

```

```{r lookAtTheTables, message=FALSE, warning = FALSE}

bikeStations <- db %>%
  dbGetQuery("SELECT *
             FROM station_summary;")

bikeStations <- bikeStations %>%
  filter(num_months > 8)

```

```{r findTheSubscriber, message=FALSE, warning = FALSE}
MinutesOfSubscriber <- db %>%
  dbGetQuery("SELECT SUM(duration) AS minutes_ridden, user_type, start_time
              FROM trips
              GROUP BY MONTH(start_time), user_type;")


# more minutes on the bike leads to more likely to get hit by a car. Customers have 3  billion minutes whereas subscribers have 11 million minutes

#This is a big query and MySQL is super slow at it. There's probably nothing wring with your computer but it did take about 2 minutes to execute on my computer.

```

```{r subscriberVSTotal, message=FALSE, warning = FALSE}
MinutesOfSubscriberClean <- MinutesOfSubscriber %>%
  mutate(month = month(start_time)) %>%
  select(-start_time) %>%
  filter(user_type != "NA")

ggplot(MinutesOfSubscriberClean, aes(x = month, y = minutes_ridden, col = user_type)) + 
  geom_line() +
  scale_y_continuous(name="Minutes ridden", labels = scales::comma) + 
  ggtitle("Citibike usage in 2017") +
  xlab("Month") + 
  labs(color = "User Type:") +
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12), labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")) +
  scale_color_manual(values = c("darkslateblue", "red")) + 
  theme_economist_white()
```


```{r ggplotViaDplyr, message=FALSE, warning = FALSE}
joinedTableSimple <- db %>%
  dbGetQuery("SELECT
                station_months.station_id AS smonID, station_months.name AS smonName, station_summary.num_months AS ssumNumMonths, station_summary.num_starts AS ssumNumStarts, station_summary.num_stops AS ssumNumStops
              FROM
                station_months
                  LEFT JOIN
                station_summary ON station_months.station_id = station_summary.station_id;")

joinedTableUniques <- joinedTableSimple %>%
  distinct()

joinedTableUniques <- joinedTableUniques %>%
  mutate(AverageMonthyUsers = (ssumNumStarts/ssumNumMonths)) %>%
  filter(ssumNumMonths == "12") %>%
  mutate(TotalCitiStarts = sum(ssumNumStarts)) %>%
  mutate(PercentOfTotal = (ssumNumStarts / TotalCitiStarts)) %>%
  arrange((desc(PercentOfTotal))) %>%
  filter(PercentOfTotal > 0.00375)

joinedTableUniques$PercentOfTotal <- joinedTableUniques$PercentOfTotal * 100

```

```{r IndividualStations, message=FALSE, warning = FALSE}

ggplot(joinedTableUniques, aes(x = reorder(smonName, PercentOfTotal), y = PercentOfTotal)) + 
  geom_col(fill = "darkslateblue", width = 0.8, position = position_dodge(width = .9)) + 
  coord_flip() +
  xlab(" ") + 
  ylab("Percent of Citi Bike trips") + 
  ggtitle("Most popular Citi Bike stations in 2017") +
  theme_economist_white()  + 
  theme(axis.text.y=element_text(size=rel(0.5)))

# impact: we can tell the Citi Bike stations are well spread out. There aren't any stations that are excessively impacted, although there are some lesser used ones.

```


```{r importSmallCrashData, message = FALSE, warning = FALSE}

nyc_crashes <- read_csv(file = "NYPD_Motor_Vehicle_CollisionsSmall.csv")

```


```{r FilterForBikeCrashOnly, message = FALSE, warning = FALSE}
nyc_crashes_bike <- nyc_crashes %>%
  filter(!is.na(LATITUDE)) %>%
  filter(!is.na(LONGITUDE)) %>%
  filter(bike_injuries > 0 | bike_deaths > 0) 
  
```


```{r GetDatesForCrashData, message = FALSE, warning = FALSE}
bike_crashes_tidy <- nyc_crashes_bike %>%
  dplyr::select(DATE, LONGITUDE, LATITUDE, bike_injuries, bike_deaths) %>%
  dplyr::mutate(FullDate = mdy(DATE)) %>%
  separate(FullDate, sep="-", into = c("year", "month", "day")) %>%
  filter(LONGITUDE != 0, LATITUDE != 0) %>%
  filter(year == 2018 | year == 2017)
```


```{r icons, message = FALSE, warning = FALSE}
bike_icon <- icons(iconUrl = "bike_icon.png", 10, 10)
```


```{r LeafletMap, message = FALSE, warning = FALSE}
leaflet(bikeStations) %>%
  addTiles() %>%
  addMarkers(~bikeStations$lon, ~bikeStations$lat, icon = bike_icon) %>%
  addCircles(~bike_crashes_tidy$LONGITUDE, bike_crashes_tidy$LATITUDE, weight = 1.5, radius = 20,
             fill = ~bike_crashes_tidy$bike_deaths, color = 'red', stroke = TRUE, fillOpacity = 1)
```

```{r tweets, message = FALSE, warning = FALSE}
citibikeTweets <- search_tweets("citibike nyc", n = 1000, include_rts = FALSE)
# you cab only collect a handful of tweets but it refreshes every 15 minutes. There is also a monthly limit.
```

```{r wrangleYeehaw, message = FALSE, warning = FALSE}
citibikeSimple <- citibikeTweets %>%
  select(status_id, screen_name, created_at, text, display_text_width, favorite_count, retweet_count, hashtags) %>%
  mutate(month = month(created_at, label = TRUE)) %>%
  mutate(day = day(created_at)) %>%
  mutate(hour = hour(created_at)) %>%
  mutate(minuteofHour = (minute(created_at))/(60)) %>%
  mutate(TimeOfDay = hour+minuteofHour)

```

```{r plot, message = FALSE, warning = FALSE}
ggplot(citibikeSimple, aes(x = TimeOfDay, y = favorite_count, color = display_text_width)) + 
  geom_point() + 
  scale_color_gradient(low="blue", high="red") +
  theme_classic() +
  ggtitle("Tweets within the last week that include Citibike and NYC") +
  xlab("Hour of day") +
  ylab('Number of favorites') +
  labs(color = "Tweet length (characters)") +
  theme(axis.title.y = element_text(angle = 0)) +
  theme_economist_white()

#this shows how many likes that each tweet recieved. Most likes occured during the rush hour of 4 to 8 pm

```

^[[Github Repository](https://github.com/SarahGillespie/sds192-mp4)
]
